"1 859 1 4206624772 ,"
"attention_mask 2 1 256 3 : input_ids 2 1 256 3 : token_type_ids 2 1 256 3 ,"
" 1000 1001 1002 1004 1005 1006 1007 1008 1009 1011 1012 1014 1016 1017 1019 1020 1022 1023 1024 1037 1039 1040 1048 1050 1051 1052 1065 1067 1068 1070 1071 1072 1074 1075 1077 1080 1081 1084 1085 1087 1088 1089 1091 1092 1094 1097 1098 1101 1102 1103 1104 1106 1107 1109 1112 1113 1116 1117 1118 1119 1120 1122 1123 1124 1125 1126 1127 1129 1130 1132 1134 1135 1137 1138 1140 1141 1142 1155 1157 1158 1166 1168 1169 1170 1183 1185 1186 1188 1189 1190 1192 1193 1195 1198 1199 1202 1203 1205 1206 1207 1209 1210 1212 1215 1216 1219 1220 1221 1222 1224 1225 1227 1230 1231 1234 1235 1236 1237 1238 1240 1241 1242 1243 1244 1245 1247 1248 1250 1252 1253 1255 1256 1258 1259 1260 1273 1275 1276 1284 1286 1287 1288 1301 1303 1304 1306 1307 1308 1310 1311 1313 1316 1317 1320 1321 1323 1324 1325 1327 1328 1330 1333 1334 1337 1338 1339 1340 1342 1343 1345 1348 1349 1352 1353 1354 1355 1356 1358 1359 1360 1361 1362 1363 1365 1366 1368 1370 1371 1373 1374 1376 1377 1378 1391 1393 1394 1402 1404 1405 1406 1419 1421 1422 1424 1425 1426 1428 1429 1431 1434 1435 1438 1439 1441 1442 1443 1445 1446 1448 1451 1452 1455 1456 1457 1458 1460 1461 1463 1466 1467 1470 1471 1472 1473 1474 1476 1477 1478 1479 1480 1481 1483 1484 1486 1488 1489 1491 1492 1494 1495 1496 1509 1511 1512 1520 1522 1523 1524 1537 1539 1540 1542 1543 1544 1546 1547 1549 1552 1553 1556 1557 1559 1560 1561 1563 1564 1566 1569 1570 1573 1574 1575 1576 1578 1579 1581 1584 1585 1588 1589 1590 1591 1592 1594 1595 1596 1597 1598 1599 1601 1602 1604 1606 1607 1609 1610 1612 1613 1614 1627 1629 1630 1638 1640 1641 1642 1655 1657 1658 1659 1660 1663 1664 1668 1669 1671 1672 1673 1674 1675 1683 1684 1686 1687 1688 1689 1690 1698 1699 1701 1702 1703 1704 1705 1713 1714 1716 1717 1718 1719 1720 1728 1729 1731 1732 1733 1734 1735 1743 1744 1746 1747 1748 1749 1750 1758 1759 1761 1762 1763 1764 1765 1773 1774 1776 1777 1778 1779 1780 1788 1789 1791 1792 1793 1794 1795 1803 1804 1806 1807 1808 1809 1810 1818 1819 1821 1822 1823 1824 1825 1833 1834 1836 1837 1838 1839 1840 203 204 205 207 209 210 212 214 218 220 221 222 223 224 225 226 239 241 242 244 245 246 248 249 251 254 255 258 259 261 262 263 265 266 268 271 272 275 276 277 278 280 281 283 286 287 290 291 292 293 294 296 297 298 299 300 301 303 304 306 308 309 311 312 314 315 316 329 331 332 340 342 343 344 357 359 360 362 363 364 366 367 369 372 373 376 377 379 380 381 383 384 386 389 390 393 394 395 396 398 399 401 404 405 408 409 410 411 412 414 415 416 417 418 419 421 422 424 426 427 429 430 432 433 434 447 449 450 458 460 461 462 475 477 478 480 481 482 484 485 487 490 491 494 495 497 498 499 501 502 504 507 508 511 512 513 514 516 517 519 522 523 526 527 528 529 530 532 533 534 535 536 537 539 540 542 544 545 547 548 550 551 552 565 567 568 576 578 579 580 593 595 596 598 599 600 602 603 605 608 609 612 613 615 616 617 619 620 622 625 626 629 630 631 632 634 635 637 640 641 644 645 646 647 648 650 651 652 653 654 655 657 658 660 662 663 665 666 668 669 670 683 685 686 694 696 697 698 711 713 714 716 717 718 720 721 723 726 727 730 731 733 734 735 737 738 740 743 744 747 748 749 750 752 753 755 758 759 762 763 764 765 766 768 769 770 771 772 773 775 776 778 780 781 783 784 786 787 788 801 803 804 812 814 815 816 829 831 832 834 835 836 838 839 841 844 845 848 849 851 852 853 855 856 858 861 862 865 866 867 868 870 871 873 876 877 880 881 882 883 884 886 887 888 889 890 891 893 894 896 898 899 901 902 904 905 906 919 921 922 930 932 933 934 947 949 950 952 953 954 956 957 959 962 963 966 967 969 970 971 973 974 976 979 980 983 984 985 986 988 989 991 994 995 998 999 attention_mask bert.embeddings.LayerNorm.bias bert.embeddings.LayerNorm.weight bert.embeddings.position_ids bert.encoder.layer.0.attention.output.LayerNorm.bias bert.encoder.layer.0.attention.output.LayerNorm.weight bert.encoder.layer.0.output.LayerNorm.bias bert.encoder.layer.0.output.LayerNorm.weight bert.encoder.layer.1.attention.output.LayerNorm.bias bert.encoder.layer.1.attention.output.LayerNorm.weight bert.encoder.layer.1.output.LayerNorm.bias bert.encoder.layer.1.output.LayerNorm.weight bert.encoder.layer.10.attention.output.LayerNorm.bias bert.encoder.layer.10.attention.output.LayerNorm.weight bert.encoder.layer.10.output.LayerNorm.bias bert.encoder.layer.10.output.LayerNorm.weight bert.encoder.layer.11.attention.output.LayerNorm.bias bert.encoder.layer.11.attention.output.LayerNorm.weight bert.encoder.layer.11.output.LayerNorm.bias bert.encoder.layer.11.output.LayerNorm.weight bert.encoder.layer.2.attention.output.LayerNorm.bias bert.encoder.layer.2.attention.output.LayerNorm.weight bert.encoder.layer.2.output.LayerNorm.bias bert.encoder.layer.2.output.LayerNorm.weight bert.encoder.layer.3.attention.output.LayerNorm.bias bert.encoder.layer.3.attention.output.LayerNorm.weight bert.encoder.layer.3.output.LayerNorm.bias bert.encoder.layer.3.output.LayerNorm.weight bert.encoder.layer.4.attention.output.LayerNorm.bias bert.encoder.layer.4.attention.output.LayerNorm.weight bert.encoder.layer.4.output.LayerNorm.bias bert.encoder.layer.4.output.LayerNorm.weight bert.encoder.layer.5.attention.output.LayerNorm.bias bert.encoder.layer.5.attention.output.LayerNorm.weight bert.encoder.layer.5.output.LayerNorm.bias bert.encoder.layer.5.output.LayerNorm.weight bert.encoder.layer.6.attention.output.LayerNorm.bias bert.encoder.layer.6.attention.output.LayerNorm.weight bert.encoder.layer.6.output.LayerNorm.bias bert.encoder.layer.6.output.LayerNorm.weight bert.encoder.layer.7.attention.output.LayerNorm.bias bert.encoder.layer.7.attention.output.LayerNorm.weight bert.encoder.layer.7.output.LayerNorm.bias bert.encoder.layer.7.output.LayerNorm.weight bert.encoder.layer.8.attention.output.LayerNorm.bias bert.encoder.layer.8.attention.output.LayerNorm.weight bert.encoder.layer.8.output.LayerNorm.bias bert.encoder.layer.8.output.LayerNorm.weight bert.encoder.layer.9.attention.output.LayerNorm.bias bert.encoder.layer.9.attention.output.LayerNorm.weight bert.encoder.layer.9.output.LayerNorm.bias bert.encoder.layer.9.output.LayerNorm.weight input_ids output_0 output_1 token_type_ids ,"
"output_0 output_1 ,"
" 375 ,"
"Unsqueeze Unsqueeze_0 1 1 attention_mask 203 1 1 ,"
"Unsqueeze Unsqueeze_1 1 1 203 204 1 2 ,"
"Cast Cast_2 1 1 204 205 0 ,"
"Sub Sub_4 1 1 205 207 0 ,"
"Mul Mul_6 1 1 207 209 1 ,"
"Gather Gather_15 1 1 input_ids 222 0 1 0 ,"
"Gather Gather_16 1 1 token_type_ids 223 0 1 0 ,"
"Add Add_17 2 1 222 223 224 1 ,"
"Add Add_19 2 1 224 225 226 1 ,"
"LayerNorm Add_30 3 1 226 bert.embeddings.LayerNorm.weight bert.embeddings.LayerNorm.bias 239 1 1e-12 ,"
"MatMul MatMul_31 1 1 239 241 1 ,"
"Add Add_32 1 1 241 242 1 ,"
"MatMul MatMul_33 1 1 239 244 1 ,"
"Add Add_34 1 1 244 245 1 ,"
"Reshape Reshape_44 2 1 245 258 259 0 4 4 0 0 2 64 0 ,"
"MatMul MatMul_45 1 1 239 261 1 ,"
"Add Add_46 1 1 261 262 1 ,"
"Reshape Reshape_56 2 1 262 275 276 0 4 4 0 0 2 64 0 ,"
"Permute Transpose_57 1 1 276 277 4 0 2 1 3 ,"
"Reshape Reshape_67 2 1 242 290 291 0 4 4 0 0 2 64 0 ,"
"Permute Transpose_68 1 1 291 292 4 0 2 1 3 ,"
"Permute Transpose_69 1 1 259 293 4 0 2 3 1 ,"
"MatMul MatMul_70 2 1 292 293 294 -1 ,"
"Mul Div_72 1 1 294 296 1 ,"
"Add Add_73 2 1 296 209 297 1 ,"
"SoftmaxCaffe Softmax_74 1 1 297 298 3 ,"
"MatMul MatMul_75 2 1 298 277 299 -1 ,"
"Permute Transpose_76 1 1 299 300 4 0 2 1 3 ,"
"Reshape Reshape_86 2 1 300 311 312 0 3 3 0 0 -1 0 ,"
"MatMul MatMul_87 1 1 312 314 1 ,"
"Add Add_88 1 1 314 315 1 ,"
"Add Add_89 2 1 315 239 316 1 ,"
"LayerNorm Add_100 3 1 316 bert.encoder.layer.0.attention.output.LayerNorm.weight bert.encoder.layer.0.attention.output.LayerNorm.bias 329 1 1e-12 ,"
"MatMul MatMul_101 1 1 329 331 1 ,"
"Add Add_102 1 1 331 332 1 ,"
"GELU Mul_110 1 1 332 340 ,"
"MatMul MatMul_111 1 1 340 342 1 ,"
"Add Add_112 1 1 342 343 1 ,"
"Add Add_113 2 1 343 329 344 1 ,"
"LayerNorm Add_124 3 1 344 bert.encoder.layer.0.output.LayerNorm.weight bert.encoder.layer.0.output.LayerNorm.bias 357 1 1e-12 ,"
"MatMul MatMul_125 1 1 357 359 1 ,"
"Add Add_126 1 1 359 360 1 ,"
"MatMul MatMul_127 1 1 357 362 1 ,"
"Add Add_128 1 1 362 363 1 ,"
"Reshape Reshape_138 2 1 363 376 377 0 4 4 0 0 2 64 0 ,"
"MatMul MatMul_139 1 1 357 379 1 ,"
"Add Add_140 1 1 379 380 1 ,"
"Reshape Reshape_150 2 1 380 393 394 0 4 4 0 0 2 64 0 ,"
"Permute Transpose_151 1 1 394 395 4 0 2 1 3 ,"
"Reshape Reshape_161 2 1 360 408 409 0 4 4 0 0 2 64 0 ,"
"Permute Transpose_162 1 1 409 410 4 0 2 1 3 ,"
"Permute Transpose_163 1 1 377 411 4 0 2 3 1 ,"
"MatMul MatMul_164 2 1 410 411 412 -1 ,"
"Mul Div_166 1 1 412 414 1 ,"
"Add Add_167 2 1 414 209 415 1 ,"
"SoftmaxCaffe Softmax_168 1 1 415 416 3 ,"
"MatMul MatMul_169 2 1 416 395 417 -1 ,"
"Permute Transpose_170 1 1 417 418 4 0 2 1 3 ,"
"Reshape Reshape_180 2 1 418 429 430 0 3 3 0 0 -1 0 ,"
"MatMul MatMul_181 1 1 430 432 1 ,"
"Add Add_182 1 1 432 433 1 ,"
"Add Add_183 2 1 433 357 434 1 ,"
"LayerNorm Add_194 3 1 434 bert.encoder.layer.1.attention.output.LayerNorm.weight bert.encoder.layer.1.attention.output.LayerNorm.bias 447 1 1e-12 ,"
"MatMul MatMul_195 1 1 447 449 1 ,"
"Add Add_196 1 1 449 450 1 ,"
"GELU Mul_204 1 1 450 458 ,"
"MatMul MatMul_205 1 1 458 460 1 ,"
"Add Add_206 1 1 460 461 1 ,"
"Add Add_207 2 1 461 447 462 1 ,"
"LayerNorm Add_218 3 1 462 bert.encoder.layer.1.output.LayerNorm.weight bert.encoder.layer.1.output.LayerNorm.bias 475 1 1e-12 ,"
"MatMul MatMul_219 1 1 475 477 1 ,"
"Add Add_220 1 1 477 478 1 ,"
"MatMul MatMul_221 1 1 475 480 1 ,"
"Add Add_222 1 1 480 481 1 ,"
"Reshape Reshape_232 2 1 481 494 495 0 4 4 0 0 2 64 0 ,"
"MatMul MatMul_233 1 1 475 497 1 ,"
"Add Add_234 1 1 497 498 1 ,"
"Reshape Reshape_244 2 1 498 511 512 0 4 4 0 0 2 64 0 ,"
"Permute Transpose_245 1 1 512 513 4 0 2 1 3 ,"
"Reshape Reshape_255 2 1 478 526 527 0 4 4 0 0 2 64 0 ,"
"Permute Transpose_256 1 1 527 528 4 0 2 1 3 ,"
"Permute Transpose_257 1 1 495 529 4 0 2 3 1 ,"
"MatMul MatMul_258 2 1 528 529 530 -1 ,"
"Mul Div_260 1 1 530 532 1 ,"
"Add Add_261 2 1 532 209 533 1 ,"
"SoftmaxCaffe Softmax_262 1 1 533 534 3 ,"
"MatMul MatMul_263 2 1 534 513 535 -1 ,"
"Permute Transpose_264 1 1 535 536 4 0 2 1 3 ,"
"Reshape Reshape_274 2 1 536 547 548 0 3 3 0 0 -1 0 ,"
"MatMul MatMul_275 1 1 548 550 1 ,"
"Add Add_276 1 1 550 551 1 ,"
"Add Add_277 2 1 551 475 552 1 ,"
"LayerNorm Add_288 3 1 552 bert.encoder.layer.2.attention.output.LayerNorm.weight bert.encoder.layer.2.attention.output.LayerNorm.bias 565 1 1e-12 ,"
"MatMul MatMul_289 1 1 565 567 1 ,"
"Add Add_290 1 1 567 568 1 ,"
"GELU Mul_298 1 1 568 576 ,"
"MatMul MatMul_299 1 1 576 578 1 ,"
"Add Add_300 1 1 578 579 1 ,"
"Add Add_301 2 1 579 565 580 1 ,"
"LayerNorm Add_312 3 1 580 bert.encoder.layer.2.output.LayerNorm.weight bert.encoder.layer.2.output.LayerNorm.bias 593 1 1e-12 ,"
"MatMul MatMul_313 1 1 593 595 1 ,"
"Add Add_314 1 1 595 596 1 ,"
"MatMul MatMul_315 1 1 593 598 1 ,"
"Add Add_316 1 1 598 599 1 ,"
"Reshape Reshape_326 2 1 599 612 613 0 4 4 0 0 2 64 0 ,"
"MatMul MatMul_327 1 1 593 615 1 ,"
"Add Add_328 1 1 615 616 1 ,"
"Reshape Reshape_338 2 1 616 629 630 0 4 4 0 0 2 64 0 ,"
"Permute Transpose_339 1 1 630 631 4 0 2 1 3 ,"
"Reshape Reshape_349 2 1 596 644 645 0 4 4 0 0 2 64 0 ,"
"Permute Transpose_350 1 1 645 646 4 0 2 1 3 ,"
"Permute Transpose_351 1 1 613 647 4 0 2 3 1 ,"
"MatMul MatMul_352 2 1 646 647 648 -1 ,"
"Mul Div_354 1 1 648 650 1 ,"
"Add Add_355 2 1 650 209 651 1 ,"
"SoftmaxCaffe Softmax_356 1 1 651 652 3 ,"
"MatMul MatMul_357 2 1 652 631 653 -1 ,"
"Permute Transpose_358 1 1 653 654 4 0 2 1 3 ,"
"Reshape Reshape_368 2 1 654 665 666 0 3 3 0 0 -1 0 ,"
"MatMul MatMul_369 1 1 666 668 1 ,"
"Add Add_370 1 1 668 669 1 ,"
"Add Add_371 2 1 669 593 670 1 ,"
"LayerNorm Add_382 3 1 670 bert.encoder.layer.3.attention.output.LayerNorm.weight bert.encoder.layer.3.attention.output.LayerNorm.bias 683 1 1e-12 ,"
"MatMul MatMul_383 1 1 683 685 1 ,"
"Add Add_384 1 1 685 686 1 ,"
"GELU Mul_392 1 1 686 694 ,"
"MatMul MatMul_393 1 1 694 696 1 ,"
"Add Add_394 1 1 696 697 1 ,"
"Add Add_395 2 1 697 683 698 1 ,"
"LayerNorm Add_406 3 1 698 bert.encoder.layer.3.output.LayerNorm.weight bert.encoder.layer.3.output.LayerNorm.bias 711 1 1e-12 ,"
"MatMul MatMul_407 1 1 711 713 1 ,"
"Add Add_408 1 1 713 714 1 ,"
"MatMul MatMul_409 1 1 711 716 1 ,"
"Add Add_410 1 1 716 717 1 ,"
"Reshape Reshape_420 2 1 717 730 731 0 4 4 0 0 2 64 0 ,"
"MatMul MatMul_421 1 1 711 733 1 ,"
"Add Add_422 1 1 733 734 1 ,"
"Reshape Reshape_432 2 1 734 747 748 0 4 4 0 0 2 64 0 ,"
"Permute Transpose_433 1 1 748 749 4 0 2 1 3 ,"
"Reshape Reshape_443 2 1 714 762 763 0 4 4 0 0 2 64 0 ,"
"Permute Transpose_444 1 1 763 764 4 0 2 1 3 ,"
"Permute Transpose_445 1 1 731 765 4 0 2 3 1 ,"
"MatMul MatMul_446 2 1 764 765 766 -1 ,"
"Mul Div_448 1 1 766 768 1 ,"
"Add Add_449 2 1 768 209 769 1 ,"
"SoftmaxCaffe Softmax_450 1 1 769 770 3 ,"
"MatMul MatMul_451 2 1 770 749 771 -1 ,"
"Permute Transpose_452 1 1 771 772 4 0 2 1 3 ,"
"Reshape Reshape_462 2 1 772 783 784 0 3 3 0 0 -1 0 ,"
"MatMul MatMul_463 1 1 784 786 1 ,"
"Add Add_464 1 1 786 787 1 ,"
"Add Add_465 2 1 787 711 788 1 ,"
"LayerNorm Add_476 3 1 788 bert.encoder.layer.4.attention.output.LayerNorm.weight bert.encoder.layer.4.attention.output.LayerNorm.bias 801 1 1e-12 ,"
"MatMul MatMul_477 1 1 801 803 1 ,"
"Add Add_478 1 1 803 804 1 ,"
"GELU Mul_486 1 1 804 812 ,"
"MatMul MatMul_487 1 1 812 814 1 ,"
"Add Add_488 1 1 814 815 1 ,"
"Add Add_489 2 1 815 801 816 1 ,"
"LayerNorm Add_500 3 1 816 bert.encoder.layer.4.output.LayerNorm.weight bert.encoder.layer.4.output.LayerNorm.bias 829 1 1e-12 ,"
"MatMul MatMul_501 1 1 829 831 1 ,"
"Add Add_502 1 1 831 832 1 ,"
"MatMul MatMul_503 1 1 829 834 1 ,"
"Add Add_504 1 1 834 835 1 ,"
"Reshape Reshape_514 2 1 835 848 849 0 4 4 0 0 2 64 0 ,"
"MatMul MatMul_515 1 1 829 851 1 ,"
"Add Add_516 1 1 851 852 1 ,"
"Reshape Reshape_526 2 1 852 865 866 0 4 4 0 0 2 64 0 ,"
"Permute Transpose_527 1 1 866 867 4 0 2 1 3 ,"
"Reshape Reshape_537 2 1 832 880 881 0 4 4 0 0 2 64 0 ,"
"Permute Transpose_538 1 1 881 882 4 0 2 1 3 ,"
"Permute Transpose_539 1 1 849 883 4 0 2 3 1 ,"
"MatMul MatMul_540 2 1 882 883 884 -1 ,"
"Mul Div_542 1 1 884 886 1 ,"
"Add Add_543 2 1 886 209 887 1 ,"
"SoftmaxCaffe Softmax_544 1 1 887 888 3 ,"
"MatMul MatMul_545 2 1 888 867 889 -1 ,"
"Permute Transpose_546 1 1 889 890 4 0 2 1 3 ,"
"Reshape Reshape_556 2 1 890 901 902 0 3 3 0 0 -1 0 ,"
"MatMul MatMul_557 1 1 902 904 1 ,"
"Add Add_558 1 1 904 905 1 ,"
"Add Add_559 2 1 905 829 906 1 ,"
"LayerNorm Add_570 3 1 906 bert.encoder.layer.5.attention.output.LayerNorm.weight bert.encoder.layer.5.attention.output.LayerNorm.bias 919 1 1e-12 ,"
"MatMul MatMul_571 1 1 919 921 1 ,"
"Add Add_572 1 1 921 922 1 ,"
"GELU Mul_580 1 1 922 930 ,"
"MatMul MatMul_581 1 1 930 932 1 ,"
"Add Add_582 1 1 932 933 1 ,"
"Add Add_583 2 1 933 919 934 1 ,"
"LayerNorm Add_594 3 1 934 bert.encoder.layer.5.output.LayerNorm.weight bert.encoder.layer.5.output.LayerNorm.bias 947 1 1e-12 ,"
"MatMul MatMul_595 1 1 947 949 1 ,"
"Add Add_596 1 1 949 950 1 ,"
"MatMul MatMul_597 1 1 947 952 1 ,"
"Add Add_598 1 1 952 953 1 ,"
"Reshape Reshape_608 2 1 953 966 967 0 4 4 0 0 2 64 0 ,"
"MatMul MatMul_609 1 1 947 969 1 ,"
"Add Add_610 1 1 969 970 1 ,"
"Reshape Reshape_620 2 1 970 983 984 0 4 4 0 0 2 64 0 ,"
"Permute Transpose_621 1 1 984 985 4 0 2 1 3 ,"
"Reshape Reshape_631 2 1 950 998 999 0 4 4 0 0 2 64 0 ,"
"Permute Transpose_632 1 1 999 1000 4 0 2 1 3 ,"
"Permute Transpose_633 1 1 967 1001 4 0 2 3 1 ,"
"MatMul MatMul_634 2 1 1000 1001 1002 -1 ,"
"Mul Div_636 1 1 1002 1004 1 ,"
"Add Add_637 2 1 1004 209 1005 1 ,"
"SoftmaxCaffe Softmax_638 1 1 1005 1006 3 ,"
"MatMul MatMul_639 2 1 1006 985 1007 -1 ,"
"Permute Transpose_640 1 1 1007 1008 4 0 2 1 3 ,"
"Reshape Reshape_650 2 1 1008 1019 1020 0 3 3 0 0 -1 0 ,"
"MatMul MatMul_651 1 1 1020 1022 1 ,"
"Add Add_652 1 1 1022 1023 1 ,"
"Add Add_653 2 1 1023 947 1024 1 ,"
"LayerNorm Add_664 3 1 1024 bert.encoder.layer.6.attention.output.LayerNorm.weight bert.encoder.layer.6.attention.output.LayerNorm.bias 1037 1 1e-12 ,"
"MatMul MatMul_665 1 1 1037 1039 1 ,"
"Add Add_666 1 1 1039 1040 1 ,"
"GELU Mul_674 1 1 1040 1048 ,"
"MatMul MatMul_675 1 1 1048 1050 1 ,"
"Add Add_676 1 1 1050 1051 1 ,"
"Add Add_677 2 1 1051 1037 1052 1 ,"
"LayerNorm Add_688 3 1 1052 bert.encoder.layer.6.output.LayerNorm.weight bert.encoder.layer.6.output.LayerNorm.bias 1065 1 1e-12 ,"
"MatMul MatMul_689 1 1 1065 1067 1 ,"
"Add Add_690 1 1 1067 1068 1 ,"
"MatMul MatMul_691 1 1 1065 1070 1 ,"
"Add Add_692 1 1 1070 1071 1 ,"
"Reshape Reshape_702 2 1 1071 1084 1085 0 4 4 0 0 2 64 0 ,"
"MatMul MatMul_703 1 1 1065 1087 1 ,"
"Add Add_704 1 1 1087 1088 1 ,"
"Reshape Reshape_714 2 1 1088 1101 1102 0 4 4 0 0 2 64 0 ,"
"Permute Transpose_715 1 1 1102 1103 4 0 2 1 3 ,"
"Reshape Reshape_725 2 1 1068 1116 1117 0 4 4 0 0 2 64 0 ,"
"Permute Transpose_726 1 1 1117 1118 4 0 2 1 3 ,"
"Permute Transpose_727 1 1 1085 1119 4 0 2 3 1 ,"
"MatMul MatMul_728 2 1 1118 1119 1120 -1 ,"
"Mul Div_730 1 1 1120 1122 1 ,"
"Add Add_731 2 1 1122 209 1123 1 ,"
"SoftmaxCaffe Softmax_732 1 1 1123 1124 3 ,"
"MatMul MatMul_733 2 1 1124 1103 1125 -1 ,"
"Permute Transpose_734 1 1 1125 1126 4 0 2 1 3 ,"
"Reshape Reshape_744 2 1 1126 1137 1138 0 3 3 0 0 -1 0 ,"
"MatMul MatMul_745 1 1 1138 1140 1 ,"
"Add Add_746 1 1 1140 1141 1 ,"
"Add Add_747 2 1 1141 1065 1142 1 ,"
"LayerNorm Add_758 3 1 1142 bert.encoder.layer.7.attention.output.LayerNorm.weight bert.encoder.layer.7.attention.output.LayerNorm.bias 1155 1 1e-12 ,"
"MatMul MatMul_759 1 1 1155 1157 1 ,"
"Add Add_760 1 1 1157 1158 1 ,"
"GELU Mul_768 1 1 1158 1166 ,"
"MatMul MatMul_769 1 1 1166 1168 1 ,"
"Add Add_770 1 1 1168 1169 1 ,"
"Add Add_771 2 1 1169 1155 1170 1 ,"
"LayerNorm Add_782 3 1 1170 bert.encoder.layer.7.output.LayerNorm.weight bert.encoder.layer.7.output.LayerNorm.bias 1183 1 1e-12 ,"
"MatMul MatMul_783 1 1 1183 1185 1 ,"
"Add Add_784 1 1 1185 1186 1 ,"
"MatMul MatMul_785 1 1 1183 1188 1 ,"
"Add Add_786 1 1 1188 1189 1 ,"
"Reshape Reshape_796 2 1 1189 1202 1203 0 4 4 0 0 2 64 0 ,"
"MatMul MatMul_797 1 1 1183 1205 1 ,"
"Add Add_798 1 1 1205 1206 1 ,"
"Reshape Reshape_808 2 1 1206 1219 1220 0 4 4 0 0 2 64 0 ,"
"Permute Transpose_809 1 1 1220 1221 4 0 2 1 3 ,"
"Reshape Reshape_819 2 1 1186 1234 1235 0 4 4 0 0 2 64 0 ,"
"Permute Transpose_820 1 1 1235 1236 4 0 2 1 3 ,"
"Permute Transpose_821 1 1 1203 1237 4 0 2 3 1 ,"
"MatMul MatMul_822 2 1 1236 1237 1238 -1 ,"
"Mul Div_824 1 1 1238 1240 1 ,"
"Add Add_825 2 1 1240 209 1241 1 ,"
"SoftmaxCaffe Softmax_826 1 1 1241 1242 3 ,"
"MatMul MatMul_827 2 1 1242 1221 1243 -1 ,"
"Permute Transpose_828 1 1 1243 1244 4 0 2 1 3 ,"
"Reshape Reshape_838 2 1 1244 1255 1256 0 3 3 0 0 -1 0 ,"
"MatMul MatMul_839 1 1 1256 1258 1 ,"
"Add Add_840 1 1 1258 1259 1 ,"
"Add Add_841 2 1 1259 1183 1260 1 ,"
"LayerNorm Add_852 3 1 1260 bert.encoder.layer.8.attention.output.LayerNorm.weight bert.encoder.layer.8.attention.output.LayerNorm.bias 1273 1 1e-12 ,"
"MatMul MatMul_853 1 1 1273 1275 1 ,"
"Add Add_854 1 1 1275 1276 1 ,"
"GELU Mul_862 1 1 1276 1284 ,"
"MatMul MatMul_863 1 1 1284 1286 1 ,"
"Add Add_864 1 1 1286 1287 1 ,"
"Add Add_865 2 1 1287 1273 1288 1 ,"
"LayerNorm Add_876 3 1 1288 bert.encoder.layer.8.output.LayerNorm.weight bert.encoder.layer.8.output.LayerNorm.bias 1301 1 1e-12 ,"
"MatMul MatMul_877 1 1 1301 1303 1 ,"
"Add Add_878 1 1 1303 1304 1 ,"
"MatMul MatMul_879 1 1 1301 1306 1 ,"
"Add Add_880 1 1 1306 1307 1 ,"
"Reshape Reshape_890 2 1 1307 1320 1321 0 4 4 0 0 2 64 0 ,"
"MatMul MatMul_891 1 1 1301 1323 1 ,"
"Add Add_892 1 1 1323 1324 1 ,"
"Reshape Reshape_902 2 1 1324 1337 1338 0 4 4 0 0 2 64 0 ,"
"Permute Transpose_903 1 1 1338 1339 4 0 2 1 3 ,"
"Reshape Reshape_913 2 1 1304 1352 1353 0 4 4 0 0 2 64 0 ,"
"Permute Transpose_914 1 1 1353 1354 4 0 2 1 3 ,"
"Permute Transpose_915 1 1 1321 1355 4 0 2 3 1 ,"
"MatMul MatMul_916 2 1 1354 1355 1356 -1 ,"
"Mul Div_918 1 1 1356 1358 1 ,"
"Add Add_919 2 1 1358 209 1359 1 ,"
"SoftmaxCaffe Softmax_920 1 1 1359 1360 3 ,"
"MatMul MatMul_921 2 1 1360 1339 1361 -1 ,"
"Permute Transpose_922 1 1 1361 1362 4 0 2 1 3 ,"
"Reshape Reshape_932 2 1 1362 1373 1374 0 3 3 0 0 -1 0 ,"
"MatMul MatMul_933 1 1 1374 1376 1 ,"
"Add Add_934 1 1 1376 1377 1 ,"
"Add Add_935 2 1 1377 1301 1378 1 ,"
"LayerNorm Add_946 3 1 1378 bert.encoder.layer.9.attention.output.LayerNorm.weight bert.encoder.layer.9.attention.output.LayerNorm.bias 1391 1 1e-12 ,"
"MatMul MatMul_947 1 1 1391 1393 1 ,"
"Add Add_948 1 1 1393 1394 1 ,"
"GELU Mul_956 1 1 1394 1402 ,"
"MatMul MatMul_957 1 1 1402 1404 1 ,"
"Add Add_958 1 1 1404 1405 1 ,"
"Add Add_959 2 1 1405 1391 1406 1 ,"
"LayerNorm Add_970 3 1 1406 bert.encoder.layer.9.output.LayerNorm.weight bert.encoder.layer.9.output.LayerNorm.bias 1419 1 1e-12 ,"
"MatMul MatMul_971 1 1 1419 1421 1 ,"
"Add Add_972 1 1 1421 1422 1 ,"
"MatMul MatMul_973 1 1 1419 1424 1 ,"
"Add Add_974 1 1 1424 1425 1 ,"
"Reshape Reshape_984 2 1 1425 1438 1439 0 4 4 0 0 2 64 0 ,"
"MatMul MatMul_985 1 1 1419 1441 1 ,"
"Add Add_986 1 1 1441 1442 1 ,"
"Reshape Reshape_996 2 1 1442 1455 1456 0 4 4 0 0 2 64 0 ,"
"Permute Transpose_997 1 1 1456 1457 4 0 2 1 3 ,"
"Reshape Reshape_1007 2 1 1422 1470 1471 0 4 4 0 0 2 64 0 ,"
"Permute Transpose_1008 1 1 1471 1472 4 0 2 1 3 ,"
"Permute Transpose_1009 1 1 1439 1473 4 0 2 3 1 ,"
"MatMul MatMul_1010 2 1 1472 1473 1474 -1 ,"
"Mul Div_1012 1 1 1474 1476 1 ,"
"Add Add_1013 2 1 1476 209 1477 1 ,"
"SoftmaxCaffe Softmax_1014 1 1 1477 1478 3 ,"
"MatMul MatMul_1015 2 1 1478 1457 1479 -1 ,"
"Permute Transpose_1016 1 1 1479 1480 4 0 2 1 3 ,"
"Reshape Reshape_1026 2 1 1480 1491 1492 0 3 3 0 0 -1 0 ,"
"MatMul MatMul_1027 1 1 1492 1494 1 ,"
"Add Add_1028 1 1 1494 1495 1 ,"
"Add Add_1029 2 1 1495 1419 1496 1 ,"
"LayerNorm Add_1040 3 1 1496 bert.encoder.layer.10.attention.output.LayerNorm.weight bert.encoder.layer.10.attention.output.LayerNorm.bias 1509 1 1e-12 ,"
"MatMul MatMul_1041 1 1 1509 1511 1 ,"
"Add Add_1042 1 1 1511 1512 1 ,"
"GELU Mul_1050 1 1 1512 1520 ,"
"MatMul MatMul_1051 1 1 1520 1522 1 ,"
"Add Add_1052 1 1 1522 1523 1 ,"
"Add Add_1053 2 1 1523 1509 1524 1 ,"
"LayerNorm Add_1064 3 1 1524 bert.encoder.layer.10.output.LayerNorm.weight bert.encoder.layer.10.output.LayerNorm.bias 1537 1 1e-12 ,"
"MatMul MatMul_1065 1 1 1537 1539 1 ,"
"Add Add_1066 1 1 1539 1540 1 ,"
"MatMul MatMul_1067 1 1 1537 1542 1 ,"
"Add Add_1068 1 1 1542 1543 1 ,"
"Reshape Reshape_1078 2 1 1543 1556 1557 0 4 4 0 0 2 64 0 ,"
"MatMul MatMul_1079 1 1 1537 1559 1 ,"
"Add Add_1080 1 1 1559 1560 1 ,"
"Reshape Reshape_1090 2 1 1560 1573 1574 0 4 4 0 0 2 64 0 ,"
"Permute Transpose_1091 1 1 1574 1575 4 0 2 1 3 ,"
"Reshape Reshape_1101 2 1 1540 1588 1589 0 4 4 0 0 2 64 0 ,"
"Permute Transpose_1102 1 1 1589 1590 4 0 2 1 3 ,"
"Permute Transpose_1103 1 1 1557 1591 4 0 2 3 1 ,"
"MatMul MatMul_1104 2 1 1590 1591 1592 -1 ,"
"Mul Div_1106 1 1 1592 1594 1 ,"
"Add Add_1107 2 1 1594 209 1595 1 ,"
"SoftmaxCaffe Softmax_1108 1 1 1595 1596 3 ,"
"MatMul MatMul_1109 2 1 1596 1575 1597 -1 ,"
"Permute Transpose_1110 1 1 1597 1598 4 0 2 1 3 ,"
"Reshape Reshape_1120 2 1 1598 1609 1610 0 3 3 0 0 -1 0 ,"
"MatMul MatMul_1121 1 1 1610 1612 1 ,"
"Add Add_1122 1 1 1612 1613 1 ,"
"Add Add_1123 2 1 1613 1537 1614 1 ,"
"LayerNorm Add_1134 3 1 1614 bert.encoder.layer.11.attention.output.LayerNorm.weight bert.encoder.layer.11.attention.output.LayerNorm.bias 1627 1 1e-12 ,"
"MatMul MatMul_1135 1 1 1627 1629 1 ,"
"Add Add_1136 1 1 1629 1630 1 ,"
"GELU Mul_1144 1 1 1630 1638 ,"
"MatMul MatMul_1145 1 1 1638 1640 1 ,"
"Add Add_1146 1 1 1640 1641 1 ,"
"Add Add_1147 2 1 1641 1627 1642 1 ,"
"LayerNorm Add_1158 3 1 1642 bert.encoder.layer.11.output.LayerNorm.weight bert.encoder.layer.11.output.LayerNorm.bias 1655 1 1e-12 ,"
"MatMul MatMul_1159 1 1 1655 1657 1 ,"
"Add Add_1160 1 1 1657 1658 1 ,"
"SplitV Split_1161 1 2 1658 1659 1660 2 2 1 1 ,"
"Squeeze Squeeze_1162 1 1 1659 output_0 1 -1 ,"
"Squeeze Squeeze_1163 1 1 1660 output_1 1 -1 ,"
